{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827d3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py #archivos h5\n",
    "from tsfresh import extract_features, select_features #extrae features en series temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdf6ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6      \\\n",
      "0    0.029938  0.061432  0.072388  0.081329  0.078033  0.089691  0.071564   \n",
      "1    0.000275  0.001160  0.001556  0.001740  0.002380  0.003693  0.004883   \n",
      "2   -0.002899 -0.003510  0.000458  0.002991  0.005920  0.007355  0.008728   \n",
      "3    0.008636  0.018158  0.015717  0.015991  0.015442  0.015564  0.014679   \n",
      "4   -0.011475 -0.022217 -0.017456 -0.018890 -0.019714 -0.021301 -0.025055   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "200 -0.051788 -0.099670 -0.074982 -0.069702 -0.053253 -0.044342 -0.030121   \n",
      "201 -0.034637 -0.058685 -0.029419 -0.077911 -0.086914 -0.061798 -0.052765   \n",
      "202 -0.006989 -0.013123 -0.010986 -0.012695 -0.012299 -0.011810 -0.012512   \n",
      "203  0.022736  0.047821  0.042450  0.042908  0.037659  0.035675  0.031708   \n",
      "204  0.013214  0.028412  0.026215  0.026337  0.024078  0.023010  0.019562   \n",
      "\n",
      "        7         8         9      ...     18520     18521     18522  \\\n",
      "0    0.072205  0.062988  0.057098  ... -0.000580  0.001617  0.003540   \n",
      "1    0.005310  0.005676  0.005310  ...  0.013000  0.009399  0.005981   \n",
      "2    0.008698  0.007507  0.005341  ... -0.014679 -0.019745 -0.022583   \n",
      "3    0.014923  0.013916  0.014008  ...  0.007874  0.006989  0.006531   \n",
      "4   -0.033569 -0.039215 -0.038483  ...  0.007263  0.008270  0.010071   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "200 -0.018738 -0.006195  0.003540  ... -0.348297 -0.365540 -0.372803   \n",
      "201 -0.051056 -0.067871 -0.053589  ... -0.002533 -0.001892 -0.000488   \n",
      "202 -0.010437 -0.009918 -0.009796  ... -0.003296 -0.003693 -0.001709   \n",
      "203  0.029572  0.026733  0.025513  ... -0.013062 -0.020386 -0.028198   \n",
      "204  0.018646  0.016052  0.015289  ... -0.025177 -0.024780 -0.024811   \n",
      "\n",
      "        18523     18524     18525     18526     18527     18528     18529  \n",
      "0    0.003662  0.002411  0.003143  0.002594  0.002045  0.002594  0.000549  \n",
      "1    0.001801 -0.002045 -0.006378 -0.010986 -0.015106 -0.019196 -0.022736  \n",
      "2   -0.023346 -0.020325 -0.014557 -0.006927  0.001343  0.008972  0.015472  \n",
      "3    0.006012  0.005066  0.005646  0.004944  0.005127  0.003754  0.003174  \n",
      "4    0.012146  0.014221  0.015442  0.015778  0.015320  0.015198  0.015656  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "200 -0.374970 -0.369476 -0.356537 -0.339111 -0.316193 -0.290375 -0.264862  \n",
      "201  0.001831  0.005249  0.008545  0.011353  0.014832  0.017334  0.019470  \n",
      "202 -0.001526  0.000275 -0.000366  0.001343  0.002380  0.001709  0.002106  \n",
      "203 -0.034363 -0.038910 -0.042328 -0.044525 -0.046478 -0.046570 -0.049988  \n",
      "204 -0.025513 -0.024963 -0.023773 -0.022858 -0.022125 -0.020447 -0.019043  \n",
      "\n",
      "[205 rows x 18530 columns]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('test.h5', 'r') as f:\n",
    "    x_h5_test= f['x'][:]\n",
    "\n",
    "x_h5_test_df = pd.DataFrame(x_h5_test[:,0,:])\n",
    "\n",
    "print(x_h5_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98e65ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parser_time_series(ds):\n",
    "    n_rows, n_cols = ds.shape\n",
    "    ids = np.repeat(np.arange(n_rows), n_cols)\n",
    "    times = np.tile(np.arange(n_cols), n_rows)\n",
    "    values = ds.values.flatten()\n",
    "    return pd.DataFrame({'id': ids, 'time': times, 'value': values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c9769fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction.settings import EfficientFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "\n",
    "_PARQUET_ENGINE_AVAILABLE = True\n",
    "try:\n",
    "    import pyarrow\n",
    "except ImportError:\n",
    "    try:\n",
    "        import fastparquet\n",
    "    except ImportError:\n",
    "        _PARQUET_ENGINE_AVAILABLE = False\n",
    "        print(\"Warning: ni pyarrow ni fastparquet disponibles\")\n",
    "\n",
    "# Extract autoajustada por batches\n",
    "def extract_features_batch(x_df: pd.DataFrame, target_ram_gb: float = 8.0, sample_ids: int = 50, output_dir: str = \"features_blocks\", n_jobs: int = None, memory_margin: float = 0.8) -> pd.DataFrame:\n",
    "    from multiprocessing import cpu_count\n",
    "\n",
    "    total_cores = cpu_count()\n",
    "    n_jobs = n_jobs or max(1, total_cores - 1)\n",
    "\n",
    "    avail_bytes = psutil.virtual_memory().available\n",
    "    target_bytes = target_ram_gb * (1024 ** 3) * memory_margin\n",
    "    max_use_bytes = min(avail_bytes * memory_margin, target_bytes)\n",
    "\n",
    "    unique_ids = x_df['id'].unique()\n",
    "    num_ids = len(unique_ids)\n",
    "\n",
    "    samp = unique_ids[:min(sample_ids, num_ids)]\n",
    "    samp_df = x_df[x_df['id'].isin(samp)]\n",
    "    sample_feats = extract_features(\n",
    "        samp_df,\n",
    "        column_id='id',\n",
    "        column_sort='time',\n",
    "        default_fc_parameters=EfficientFCParameters(),\n",
    "        n_jobs=1\n",
    "    )\n",
    "    mem_usage = sample_feats.memory_usage(deep=True).sum()\n",
    "    per_id = mem_usage / len(samp)\n",
    "\n",
    "    block_size = max(1, int(max_use_bytes / per_id))\n",
    "    block_size = min(block_size, num_ids)\n",
    "    print(f\"Usable RAM estimada: {max_use_bytes/1e9:.2f} GB, memoria/ID: {per_id/1e6:.2f} MB -> block_size = {block_size}\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx in range(0, num_ids, block_size):\n",
    "        batch = unique_ids[idx: idx + block_size]\n",
    "        block_df = x_df[x_df['id'].isin(batch)]\n",
    "        feats = extract_features(\n",
    "            block_df,\n",
    "            column_id='id',\n",
    "            column_sort='time',\n",
    "            default_fc_parameters=EfficientFCParameters(),\n",
    "            n_jobs=n_jobs,\n",
    "            chunksize=max(1, block_size // n_jobs)\n",
    "        )\n",
    "        fname_base = f\"{output_dir}/block_{idx//block_size:04d}\"\n",
    "        if _PARQUET_ENGINE_AVAILABLE:\n",
    "            feats.to_parquet(fname_base + \".parquet\")\n",
    "        else:\n",
    "            feats.to_csv(fname_base + \".csv\", index=False)\n",
    "        print(f\"Guardado bloque {idx//block_size + 1} con {len(batch)} IDs\")\n",
    "\n",
    "    all_frames = []\n",
    "    for fpath in glob.glob(f\"{output_dir}/block_*.{'parquet' if _PARQUET_ENGINE_AVAILABLE else 'csv'}\"):\n",
    "        if fpath.endswith('.parquet'):\n",
    "            all_frames.append(pd.read_parquet(fpath))\n",
    "        else:\n",
    "            all_frames.append(pd.read_csv(fpath))\n",
    "\n",
    "    all_feats = pd.concat(all_frames, ignore_index=True)\n",
    "    return all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1e4fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_parser = parser_time_series(x_h5_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "024a85c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id   time     value\n",
      "0          0      0  0.029938\n",
      "1          0      1  0.061432\n",
      "2          0      2  0.072388\n",
      "3          0      3  0.081329\n",
      "4          0      4  0.078033\n",
      "...      ...    ...       ...\n",
      "3798645  204  18525 -0.023773\n",
      "3798646  204  18526 -0.022858\n",
      "3798647  204  18527 -0.022125\n",
      "3798648  204  18528 -0.020447\n",
      "3798649  204  18529 -0.019043\n",
      "\n",
      "[3798650 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14b4236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 50/50 [01:25<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable RAM estimada: 3.83 GB, memoria/ID: 0.01 MB -> block_size = 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 10/10 [01:21<00:00,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado bloque 1 con 205 IDs\n",
      "     value__variance_larger_than_standard_deviation  value__has_duplicate_max  \\\n",
      "0                                               0.0                       0.0   \n",
      "1                                               0.0                       0.0   \n",
      "2                                               0.0                       0.0   \n",
      "3                                               0.0                       0.0   \n",
      "4                                               0.0                       0.0   \n",
      "..                                              ...                       ...   \n",
      "200                                             0.0                       0.0   \n",
      "201                                             0.0                       0.0   \n",
      "202                                             0.0                       0.0   \n",
      "203                                             0.0                       1.0   \n",
      "204                                             0.0                       0.0   \n",
      "\n",
      "     value__has_duplicate_min  value__has_duplicate  value__sum_values  \\\n",
      "0                         0.0                   1.0          -1.108182   \n",
      "1                         0.0                   1.0          -2.736053   \n",
      "2                         0.0                   1.0          -0.200805   \n",
      "3                         0.0                   1.0          -0.108185   \n",
      "4                         0.0                   1.0          -0.873899   \n",
      "..                        ...                   ...                ...   \n",
      "200                       0.0                   1.0          -0.755006   \n",
      "201                       0.0                   1.0          -1.070435   \n",
      "202                       0.0                   1.0          -0.535217   \n",
      "203                       1.0                   1.0           0.436249   \n",
      "204                       0.0                   1.0          -0.819764   \n",
      "\n",
      "     value__abs_energy  value__mean_abs_change  value__mean_change  \\\n",
      "0           188.142145                0.008619       -1.586077e-06   \n",
      "1             2.089645                0.000988       -1.241851e-06   \n",
      "2             8.075229                0.002489        9.915041e-07   \n",
      "3             7.379380                0.001721       -2.948161e-07   \n",
      "4            32.803556                0.003637        1.464198e-06   \n",
      "..                 ...                     ...                 ...   \n",
      "200          34.531892                0.003123       -1.149947e-05   \n",
      "201          30.030232                0.004201        2.920161e-06   \n",
      "202           3.653319                0.001533        4.908111e-07   \n",
      "203         541.902821                0.012449       -3.924842e-06   \n",
      "204          85.552530                0.004274       -1.740897e-06   \n",
      "\n",
      "     value__mean_second_derivative_central  value__median  ...  \\\n",
      "0                            -9.050847e-07      -0.000534  ...   \n",
      "1                            -1.194152e-07      -0.000214  ...   \n",
      "2                             1.918878e-07      -0.000031  ...   \n",
      "3                            -2.725960e-07       0.000305  ...   \n",
      "4                             3.022442e-07       0.000244  ...   \n",
      "..                                     ...            ...  ...   \n",
      "200                           1.980645e-06       0.000000  ...   \n",
      "201                           7.066084e-07       0.001678  ...   \n",
      "202                           1.762404e-07      -0.000153  ...   \n",
      "203                          -7.691982e-07      -0.000793  ...   \n",
      "204                          -3.722461e-07      -0.000183  ...   \n",
      "\n",
      "     value__fourier_entropy__bins_5  value__fourier_entropy__bins_10  \\\n",
      "0                          0.249958                         0.350689   \n",
      "1                          0.318449                         0.418924   \n",
      "2                          0.344487                         0.482843   \n",
      "3                          0.341853                         0.404122   \n",
      "4                          0.249958                         0.294982   \n",
      "..                              ...                              ...   \n",
      "200                        0.239211                         0.305728   \n",
      "201                        0.215617                         0.305728   \n",
      "202                        0.239211                         0.380783   \n",
      "203                        0.288307                         0.397431   \n",
      "204                        0.136002                         0.215617   \n",
      "\n",
      "     value__fourier_entropy__bins_100  \\\n",
      "0                            0.709399   \n",
      "1                            0.741638   \n",
      "2                            1.042906   \n",
      "3                            0.730892   \n",
      "4                            0.730892   \n",
      "..                                ...   \n",
      "200                          0.574520   \n",
      "201                          0.559717   \n",
      "202                          0.763720   \n",
      "203                          0.815355   \n",
      "204                          0.474437   \n",
      "\n",
      "     value__permutation_entropy__dimension_3__tau_1  \\\n",
      "0                                          1.088459   \n",
      "1                                          1.330092   \n",
      "2                                          1.168164   \n",
      "3                                          1.336187   \n",
      "4                                          1.195760   \n",
      "..                                              ...   \n",
      "200                                        1.454446   \n",
      "201                                        1.302857   \n",
      "202                                        1.710468   \n",
      "203                                        1.135978   \n",
      "204                                        1.360193   \n",
      "\n",
      "     value__permutation_entropy__dimension_4__tau_1  \\\n",
      "0                                          1.526443   \n",
      "1                                          1.976669   \n",
      "2                                          1.690916   \n",
      "3                                          1.956122   \n",
      "4                                          1.757735   \n",
      "..                                              ...   \n",
      "200                                        2.196857   \n",
      "201                                        1.983106   \n",
      "202                                        2.830508   \n",
      "203                                        1.623449   \n",
      "204                                        2.058467   \n",
      "\n",
      "     value__permutation_entropy__dimension_5__tau_1  \\\n",
      "0                                          1.999193   \n",
      "1                                          2.669299   \n",
      "2                                          2.254095   \n",
      "3                                          2.605742   \n",
      "4                                          2.367109   \n",
      "..                                              ...   \n",
      "200                                        2.947505   \n",
      "201                                        2.713239   \n",
      "202                                        4.024168   \n",
      "203                                        2.152053   \n",
      "204                                        2.794245   \n",
      "\n",
      "     value__permutation_entropy__dimension_6__tau_1  \\\n",
      "0                                          2.495490   \n",
      "1                                          3.388526   \n",
      "2                                          2.840535   \n",
      "3                                          3.274465   \n",
      "4                                          3.005979   \n",
      "..                                              ...   \n",
      "200                                        3.717414   \n",
      "201                                        3.476477   \n",
      "202                                        5.281193   \n",
      "203                                        2.708795   \n",
      "204                                        3.558363   \n",
      "\n",
      "     value__permutation_entropy__dimension_7__tau_1  \\\n",
      "0                                          3.012450   \n",
      "1                                          4.093002   \n",
      "2                                          3.439813   \n",
      "3                                          3.914495   \n",
      "4                                          3.652811   \n",
      "..                                              ...   \n",
      "200                                        4.430254   \n",
      "201                                        4.213253   \n",
      "202                                        6.489290   \n",
      "203                                        3.276811   \n",
      "204                                        4.285635   \n",
      "\n",
      "     value__query_similarity_count__query_None__threshold_0.0  \\\n",
      "0                                                  NaN          \n",
      "1                                                  NaN          \n",
      "2                                                  NaN          \n",
      "3                                                  NaN          \n",
      "4                                                  NaN          \n",
      "..                                                 ...          \n",
      "200                                                NaN          \n",
      "201                                                NaN          \n",
      "202                                                NaN          \n",
      "203                                                NaN          \n",
      "204                                                NaN          \n",
      "\n",
      "     value__mean_n_absolute_max__number_of_maxima_7  \n",
      "0                                          0.544525  \n",
      "1                                          0.076551  \n",
      "2                                          0.126382  \n",
      "3                                          0.125427  \n",
      "4                                          0.284114  \n",
      "..                                              ...  \n",
      "200                                        0.384565  \n",
      "201                                        0.197484  \n",
      "202                                        0.158020  \n",
      "203                                        1.000000  \n",
      "204                                        0.370536  \n",
      "\n",
      "[205 rows x 777 columns]\n",
      "(205, 777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_features = extract_features_batch(X_test_parser)\n",
    "print(X_test_features)\n",
    "print(X_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features estandarizadas (205, 777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# NO Estandarizar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_test_features)\n",
    "X_scaled_test_df = pd.DataFrame(X_scaled)\n",
    "\n",
    "print(\"Features estandarizadas\", X_scaled_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# NOEstandarizar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_test_features)\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X_test_features.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad8ef468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features estandarizadas y filtradas: (205, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/nahiaescalante/Documents/2025/ML/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# Estandarizar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_test_features)\n",
    "\n",
    "X_scaled_test_df_full = pd.DataFrame(X_scaled, columns=X_test_features.columns)\n",
    "\n",
    "X_train = pd.read_csv(\"features_40.csv\")\n",
    "\n",
    "X_scaled_test_df = X_scaled_test_df_full[X_train.columns]\n",
    "\n",
    "print(\"Features estandarizadas y filtradas:\", X_scaled_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c823f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_test_df.to_csv('x_test_40.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
